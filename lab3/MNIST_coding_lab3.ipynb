{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ChatGPT - MNIST model"
      ],
      "metadata": {
        "id": "kWmosnsnGVIW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeeD8BmC9aPy",
        "outputId": "ca30a13f-34de-46a1-d777-0144a020e711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2579 - accuracy: 0.9262\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1114 - accuracy: 0.9670\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0764 - accuracy: 0.9764\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0563 - accuracy: 0.9836\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0437 - accuracy: 0.9865\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0801 - accuracy: 0.9769\n",
            "Test accuracy: 0.9768999814987183\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "# Reshape the data to fit the input shape of the neural network and normalize it to values between 0 and 1\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# Convert labels to one-hot encoded format\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
        "\n",
        "# Define the neural network model\n",
        "model = models.Sequential()\n",
        "# Add a Flatten layer to convert the 2D image data into a 1D array\n",
        "model.add(layers.Flatten(input_shape=(28, 28, 1)))\n",
        "# Add a Dense layer with 128 units and ReLU activation function\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "# Add a Dense layer with 10 units (for 10 classes) and softmax activation function for classification\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "# Use the Adam optimizer, categorical crossentropy as the loss function, and track accuracy as a metric\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "# Use the training data and labels, batch size of 32, and train for 5 epochs\n",
        "model.fit(train_images, train_labels, batch_size=32, epochs=5)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy: {test_acc}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Book - MNIST model"
      ],
      "metadata": {
        "id": "WDgHPnjNGm9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the MNIST dataset from TensorFlow's Keras API\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Loading the MNIST dataset into training and testing sets\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Importing necessary modules from TensorFlow for building the neural network\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Defining the neural network model using Keras' Sequential API\n",
        "# The model consists of two dense layers:\n",
        "# - The first dense layer has 512 neurons and uses the ReLU activation function\n",
        "# - The second dense layer has 10 neurons (representing the 10 digits) and uses the softmax activation function for classification\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compiling the model with the following specifications:\n",
        "# - Optimizer: RMSprop\n",
        "# - Loss function: Sparse Categorical Crossentropy (suitable for integer labels)\n",
        "# - Metrics: Accuracy (to monitor during training)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Preprocessing the training images:\n",
        "# - Reshaping the images from 28x28 matrices to flat vectors of size 784 (28*28)\n",
        "# - Normalizing the pixel values to be between 0 and 1 by dividing by 255\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "# Preprocessing the testing images in the same way as the training images\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255\n",
        "\n",
        "# Training the model using the preprocessed training images and labels\n",
        "# - Epochs: 5 (number of times the model will see the entire dataset)\n",
        "# - Batch size: 128 (number of samples processed before updating the model's weights)\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
        "\n",
        "# Extracting the first 10 test images for prediction\n",
        "test_digits = test_images[0:10]\n",
        "\n",
        "# Predicting the class probabilities for the extracted test images\n",
        "predictions = model.predict(test_digits)\n",
        "\n",
        "# Displaying the predicted class probabilities for the first test image\n",
        "print(predictions[0])\n",
        "\n",
        "# Finding the class with the highest probability for the first test image\n",
        "print(predictions[0].argmax())\n",
        "\n",
        "# Displaying the probability of the class 7 for the first test image\n",
        "print(predictions[0][7])\n",
        "\n",
        "# Evaluating the model's performance on the entire test set\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "# Printing the accuracy of the model on the test set\n",
        "print(f\"test_acc: {test_acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqHOTz6cGk4Q",
        "outputId": "d6fd9be7-48fa-42ff-b077-1ae5674aeb1d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.2672 - accuracy: 0.9224\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1089 - accuracy: 0.9681\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0719 - accuracy: 0.9788\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.0519 - accuracy: 0.9843\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0392 - accuracy: 0.9883\n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "[3.27006831e-08 1.71879311e-08 1.99961341e-05 4.68345315e-05\n",
            " 9.22495587e-12 1.16408046e-07 1.15397657e-11 9.99931753e-01\n",
            " 6.76901522e-08 1.08296399e-06]\n",
            "7\n",
            "0.99993175\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0613 - accuracy: 0.9803\n",
            "test_acc: 0.9803000092506409\n"
          ]
        }
      ]
    }
  ]
}